{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1NZbUu0I7hz",
        "outputId": "ddf20cef-8929-4fcb-cdb0-fbe3a22debf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whisper\n",
            "  Downloading whisper-1.1.10.tar.gz (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from whisper) (1.16.0)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.1.10-py3-none-any.whl size=41120 sha256=78096b3e25de93ceb49e02842dd5802c8092a18879d618eb1777c274e07d1d94\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/7c/1d/015619716e2facae6631312503baf3c3220e6a9a3508cb14b6\n",
            "Successfully built whisper\n",
            "Installing collected packages: whisper\n",
            "Successfully installed whisper-1.1.10\n"
          ]
        }
      ],
      "source": [
        "!pip install whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94a4UR8iEx-G",
        "outputId": "988d347f-237b-45fd-f6bf-b669ae12756b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets[audio]\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Collecting pyarrow>=12.0.0 (from datasets[audio])\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.4.1)\n",
            "Collecting multiprocess (from datasets[audio])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets[audio]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.9.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2023.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa->datasets[audio]) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, dill, multiprocess, accelerate, transformers, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.27.2 datasets-2.17.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-15.0.0 transformers-4.37.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade transformers accelerate datasets[audio]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHyDC6deFYy9",
        "outputId": "83096e32-f750-4df9-d7b0-a98c3ec35382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "# from datasets import load_dataset\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"distil-whisper/distil-large-v2\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "# dataset = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "# sample = dataset[0][\"audio\"]\n",
        "\n",
        "# result = pipe(sample)\n",
        "# print(result[\"text\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyvDeGsGwexI",
        "outputId": "da0f1ced-4378-4dfd-943d-f2cbf962b98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.9.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C11tqO1AZuBu",
        "outputId": "b3664d12-3376-41dd-f03e-52df61ebea8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=3cb12787e647be9b261e893edd641878c8441b4548ade7c3f50ec18c23675d6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting setuptools-rust\n",
            "  Downloading setuptools_rust-1.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: setuptools>=62.4 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (67.7.2)\n",
            "Collecting semantic-version<3,>=2.8.2 (from setuptools-rust)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tomli>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from setuptools-rust) (2.0.1)\n",
            "Downloading setuptools_rust-1.8.1-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: semantic-version, setuptools-rust\n",
            "Successfully installed semantic-version-2.10.0 setuptools-rust-1.8.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.47-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-4.47-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: importlib_metadata, h11, fastavro, backoff, httpcore, httpx, cohere, openai\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed backoff-2.2.1 cohere-4.47 fastavro-1.9.4 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 importlib_metadata-6.11.0 openai-1.12.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "!pip install pytube\n",
        "!pip install -U openai-whisper\n",
        "!pip install setuptools-rust\n",
        "!pip install openai cohere\n",
        "\n",
        "import whisper\n",
        "from pytube import YouTube\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVkB1nIiZav-"
      },
      "outputs": [],
      "source": [
        "def audio_youtube(url):\n",
        "    yt = YouTube(url)\n",
        "    video = yt.streams.filter(only_audio=True).first()\n",
        "    destino = \"temp_audio\"\n",
        "    out_file = video.download(output_path=destino)\n",
        "    base, ext = os.path.splitext(out_file)\n",
        "\n",
        "    audio = AudioSegment.from_file(out_file)\n",
        "    new_file = base + '.mp3'\n",
        "    audio.export(new_file, format='mp3')\n",
        "\n",
        "\n",
        "    os.remove(out_file)\n",
        "    print(new_file)\n",
        "\n",
        "    return new_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RYIPHWkyP_Z",
        "outputId": "9909c107-22ad-4233-d4f9-de55d1de4b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/temp_audio/Best Short Motivational Speech Video - 24 HOURS - 1-Minute Motivation 2.mp3\n"
          ]
        }
      ],
      "source": [
        "audio =audio_youtube('https://www.youtube.com/watch?v=fLeJJPxua3E')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwYwxQSFx7zS"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "# Load the audio file\n",
        "audio_file_path = audio  # Replace with the path to your audio file\n",
        "y, sr = librosa.load(audio_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFZf4fVA5esD",
        "outputId": "91a9debd-7bf6-4da6-cfa3-98d1db2d25da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0000000e+00 0.0000000e+00 0.0000000e+00 ... 2.4096902e-05 5.6095923e-06\n",
            " 1.7617678e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPAOCI_YGNri",
        "outputId": "8a09894c-29b6-4f12-eea8-41c66cde87ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `None` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-84b0bd1f5f08>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult_whisper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_whisper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_whisper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/automatic_speech_recognition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                     \u001b[0;31m`\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"chunks\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     def _sanitize_parameters(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mChunkPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             return next(\n\u001b[0m\u001b[1;32m   1155\u001b[0m                 iter(\n\u001b[1;32m   1156\u001b[0m                     self.get_iterator(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1066\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/automatic_speech_recognition.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, return_timestamps, generate_kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             tokens = self.model.generate(\n\u001b[0m\u001b[1;32m    508\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;31m# 6.8 Run generate with fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             seek_sequences, seek_outputs, should_skip, do_condition_on_prev_tokens = self.generate_with_fallback(\n\u001b[0m\u001b[1;32m    642\u001b[0m                 \u001b[0msegment_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py\u001b[0m in \u001b[0;36mgenerate_with_fallback\u001b[0;34m(self, segment_input, decoder_input_ids, cur_bsz, batch_idx_map, seek, num_segment_frames, max_frames, temperatures, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_token_timestamps, do_condition_on_prev_tokens, kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_beams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_beams\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_sample\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             seek_outputs = super().generate(\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0msegment_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1368\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1371\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                     )\n\u001b[1;32m   1214\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m   1216\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                         \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         hidden_states, attn_weights, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    772\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/modeling_whisper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;31m# self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#insanely fast whisper\n",
        "\n",
        "\n",
        "# print(y)\n",
        "result_whisper = pipe(y)\n",
        "print(result_whisper)\n",
        "print(result_whisper[\"text\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vDMvdhZKCm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1hIlG0mCF9l",
        "outputId": "e46a2034-5d3d-4934-b602-14bd801d614a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 50.8MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" If you only have 24 hours in a day, your success is dependent upon how you use the 24. You gotta hear me. People talk about open-air free, you know, care-turner, warm-buffet. Listen to me. I don't care how much money you make. You only get 24 hours in a day. And the difference between Oprah and the person that's broke is Oprah uses her 24 hours wisely. That's it. Listen to me. That's it. You get 24. I don't care if you broke, you grew up broke. I don't care if you grew up rich. I don't care if you're in college. You're not in college. You only get 24 hours and I blew up literally. I went from being a high school dropout to selling 6,000 books and less than six months. What happened? My 24 hours. I was like, okay, Eric, you gotta get a grip on your 24 hours because you're about to be broke for the rest of your life. And that's all I need you to do for me. I can tell you all about your life. If you just write down your 24-hour schedule for me, you let me look at it. I can tell you where you're going to be in five years. I can tell you where you're going to be in ten years. I can tell you where you're going to be in 20 years if you keep that schedule.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.04, 'text': ' If you only have 24 hours in a day, your success is dependent upon how you use the 24.', 'tokens': [50364, 759, 291, 787, 362, 4022, 2496, 294, 257, 786, 11, 428, 2245, 307, 12334, 3564, 577, 291, 764, 264, 4022, 13, 50731], 'temperature': 0.0, 'avg_logprob': -0.3344689178466797, 'compression_ratio': 1.5663716814159292, 'no_speech_prob': 0.16464950144290924, 'words': [{'word': ' If', 'start': 0.0, 'end': 0.32, 'probability': 0.4307107925415039}, {'word': ' you', 'start': 0.32, 'end': 0.48, 'probability': 0.9927681684494019}, {'word': ' only', 'start': 0.48, 'end': 0.84, 'probability': 0.9951589703559875}, {'word': ' have', 'start': 0.84, 'end': 1.24, 'probability': 0.9822304844856262}, {'word': ' 24', 'start': 1.24, 'end': 1.94, 'probability': 0.9615322351455688}, {'word': ' hours', 'start': 1.94, 'end': 2.44, 'probability': 0.9925803542137146}, {'word': ' in', 'start': 2.44, 'end': 2.6, 'probability': 0.914588451385498}, {'word': ' a', 'start': 2.6, 'end': 2.7, 'probability': 0.9596467614173889}, {'word': ' day,', 'start': 2.7, 'end': 3.0, 'probability': 0.9991512298583984}, {'word': ' your', 'start': 3.4, 'end': 3.72, 'probability': 0.9559580087661743}, {'word': ' success', 'start': 3.72, 'end': 4.32, 'probability': 0.9974702596664429}, {'word': ' is', 'start': 4.32, 'end': 4.76, 'probability': 0.9854331612586975}, {'word': ' dependent', 'start': 4.76, 'end': 5.18, 'probability': 0.6948895454406738}, {'word': ' upon', 'start': 5.18, 'end': 5.6, 'probability': 0.9904767274856567}, {'word': ' how', 'start': 5.6, 'end': 6.08, 'probability': 0.996300458908081}, {'word': ' you', 'start': 6.08, 'end': 6.24, 'probability': 0.996250331401825}, {'word': ' use', 'start': 6.24, 'end': 6.46, 'probability': 0.7939143776893616}, {'word': ' the', 'start': 6.46, 'end': 6.56, 'probability': 0.9649363160133362}, {'word': ' 24.', 'start': 6.56, 'end': 7.04, 'probability': 0.9847902655601501}]}, {'id': 1, 'seek': 0, 'start': 8.1, 'end': 13.34, 'text': ' You gotta hear me. People talk about open-air free, you know, care-turner, warm-buffet. Listen to me.', 'tokens': [50782, 509, 3428, 1568, 385, 13, 3432, 751, 466, 1269, 12, 1246, 1737, 11, 291, 458, 11, 1127, 12, 33886, 260, 11, 4561, 12, 65, 1245, 302, 13, 7501, 281, 385, 13, 51036], 'temperature': 0.0, 'avg_logprob': -0.3344689178466797, 'compression_ratio': 1.5663716814159292, 'no_speech_prob': 0.16464950144290924, 'words': [{'word': ' You', 'start': 8.1, 'end': 8.58, 'probability': 0.9777253866195679}, {'word': ' gotta', 'start': 8.58, 'end': 8.72, 'probability': 0.5602847337722778}, {'word': ' hear', 'start': 8.72, 'end': 8.94, 'probability': 0.9949920773506165}, {'word': ' me.', 'start': 8.94, 'end': 9.06, 'probability': 0.9959262609481812}, {'word': ' People', 'start': 9.12, 'end': 9.26, 'probability': 0.9860334992408752}, {'word': ' talk', 'start': 9.26, 'end': 9.44, 'probability': 0.8385158181190491}, {'word': ' about', 'start': 9.44, 'end': 9.66, 'probability': 0.9971476197242737}, {'word': ' open', 'start': 9.66, 'end': 9.94, 'probability': 0.760871171951294}, {'word': '-air', 'start': 9.94, 'end': 10.16, 'probability': 0.16430959850549698}, {'word': ' free,', 'start': 10.16, 'end': 10.42, 'probability': 0.5093425512313843}, {'word': ' you', 'start': 10.66, 'end': 10.84, 'probability': 0.8540127873420715}, {'word': ' know,', 'start': 10.84, 'end': 10.94, 'probability': 0.9783979654312134}, {'word': ' care', 'start': 11.1, 'end': 11.2, 'probability': 0.372640997171402}, {'word': '-turner,', 'start': 11.2, 'end': 11.76, 'probability': 0.6836721499760946}, {'word': ' warm', 'start': 12.12, 'end': 12.24, 'probability': 0.6034963130950928}, {'word': '-buffet.', 'start': 12.24, 'end': 12.74, 'probability': 0.7492397502064705}, {'word': ' Listen', 'start': 12.84, 'end': 12.94, 'probability': 0.9662761092185974}, {'word': ' to', 'start': 12.94, 'end': 13.18, 'probability': 0.9934241771697998}, {'word': ' me.', 'start': 13.18, 'end': 13.34, 'probability': 0.9996381998062134}]}, {'id': 2, 'seek': 0, 'start': 13.58, 'end': 16.76, 'text': \" I don't care how much money you make. You only get 24 hours in a day.\", 'tokens': [51036, 286, 500, 380, 1127, 577, 709, 1460, 291, 652, 13, 509, 787, 483, 4022, 2496, 294, 257, 786, 13, 51210], 'temperature': 0.0, 'avg_logprob': -0.3344689178466797, 'compression_ratio': 1.5663716814159292, 'no_speech_prob': 0.16464950144290924, 'words': [{'word': ' I', 'start': 13.58, 'end': 13.64, 'probability': 0.6029961109161377}, {'word': \" don't\", 'start': 13.64, 'end': 13.76, 'probability': 0.9793708622455597}, {'word': ' care', 'start': 13.76, 'end': 13.84, 'probability': 0.9954220652580261}, {'word': ' how', 'start': 13.84, 'end': 14.06, 'probability': 0.9831693172454834}, {'word': ' much', 'start': 14.06, 'end': 14.22, 'probability': 0.996721088886261}, {'word': ' money', 'start': 14.22, 'end': 14.48, 'probability': 0.9950679540634155}, {'word': ' you', 'start': 14.48, 'end': 14.62, 'probability': 0.9952256679534912}, {'word': ' make.', 'start': 14.62, 'end': 14.82, 'probability': 0.7877002358436584}, {'word': ' You', 'start': 15.16, 'end': 15.22, 'probability': 0.9960867166519165}, {'word': ' only', 'start': 15.22, 'end': 15.44, 'probability': 0.9571509957313538}, {'word': ' get', 'start': 15.44, 'end': 15.62, 'probability': 0.9921422004699707}, {'word': ' 24', 'start': 15.62, 'end': 16.1, 'probability': 0.9952499866485596}, {'word': ' hours', 'start': 16.1, 'end': 16.36, 'probability': 0.9982993006706238}, {'word': ' in', 'start': 16.36, 'end': 16.48, 'probability': 0.9661778211593628}, {'word': ' a', 'start': 16.48, 'end': 16.56, 'probability': 0.989361584186554}, {'word': ' day.', 'start': 16.56, 'end': 16.76, 'probability': 0.9992746710777283}]}, {'id': 3, 'seek': 0, 'start': 16.96, 'end': 23.44, 'text': \" And the difference between Oprah and the person that's broke is Oprah uses her 24 hours wisely.\", 'tokens': [51210, 400, 264, 2649, 1296, 43804, 293, 264, 954, 300, 311, 6902, 307, 43804, 4960, 720, 4022, 2496, 37632, 13, 51560], 'temperature': 0.0, 'avg_logprob': -0.3344689178466797, 'compression_ratio': 1.5663716814159292, 'no_speech_prob': 0.16464950144290924, 'words': [{'word': ' And', 'start': 16.96, 'end': 17.16, 'probability': 0.8950263857841492}, {'word': ' the', 'start': 17.16, 'end': 17.24, 'probability': 0.9163233041763306}, {'word': ' difference', 'start': 17.24, 'end': 17.5, 'probability': 0.9984270334243774}, {'word': ' between', 'start': 17.5, 'end': 17.86, 'probability': 0.9988254904747009}, {'word': ' Oprah', 'start': 17.86, 'end': 18.38, 'probability': 0.802302896976471}, {'word': ' and', 'start': 18.38, 'end': 18.74, 'probability': 0.9887162446975708}, {'word': ' the', 'start': 18.74, 'end': 18.86, 'probability': 0.994222104549408}, {'word': ' person', 'start': 18.86, 'end': 19.22, 'probability': 0.9992198944091797}, {'word': \" that's\", 'start': 19.22, 'end': 19.5, 'probability': 0.9749172925949097}, {'word': ' broke', 'start': 19.5, 'end': 19.84, 'probability': 0.9969164133071899}, {'word': ' is', 'start': 19.84, 'end': 20.5, 'probability': 0.8815601468086243}, {'word': ' Oprah', 'start': 20.5, 'end': 20.98, 'probability': 0.9842380881309509}, {'word': ' uses', 'start': 20.98, 'end': 21.34, 'probability': 0.8821362257003784}, {'word': ' her', 'start': 21.34, 'end': 21.58, 'probability': 0.9985120892524719}, {'word': ' 24', 'start': 21.58, 'end': 22.14, 'probability': 0.998095691204071}, {'word': ' hours', 'start': 22.14, 'end': 22.72, 'probability': 0.962317168712616}, {'word': ' wisely.', 'start': 22.72, 'end': 23.44, 'probability': 0.996392548084259}]}, {'id': 4, 'seek': 2344, 'start': 24.94, 'end': 30.18, 'text': \" That's it. Listen to me. That's it. You get 24. I don't care if you broke, you grew up broke.\", 'tokens': [50364, 663, 311, 309, 13, 7501, 281, 385, 13, 663, 311, 309, 13, 509, 483, 4022, 13, 286, 500, 380, 1127, 498, 291, 6902, 11, 291, 6109, 493, 6902, 13, 50704], 'temperature': 0.0, 'avg_logprob': -0.21133507777304544, 'compression_ratio': 1.8045977011494252, 'no_speech_prob': 0.1699000895023346, 'words': [{'word': \" That's\", 'start': 24.94, 'end': 25.3, 'probability': 0.5188685730099678}, {'word': ' it.', 'start': 25.3, 'end': 25.4, 'probability': 0.9778802394866943}, {'word': ' Listen', 'start': 25.56, 'end': 25.68, 'probability': 0.9363419413566589}, {'word': ' to', 'start': 25.68, 'end': 25.9, 'probability': 0.9696637988090515}, {'word': ' me.', 'start': 25.9, 'end': 26.08, 'probability': 0.9985772371292114}, {'word': \" That's\", 'start': 26.3, 'end': 26.56, 'probability': 0.8768457770347595}, {'word': ' it.', 'start': 26.56, 'end': 26.66, 'probability': 0.9968587160110474}, {'word': ' You', 'start': 26.82, 'end': 26.88, 'probability': 0.9821038842201233}, {'word': ' get', 'start': 26.88, 'end': 27.02, 'probability': 0.8673226833343506}, {'word': ' 24.', 'start': 27.02, 'end': 27.58, 'probability': 0.8043439984321594}, {'word': ' I', 'start': 28.08, 'end': 28.22, 'probability': 0.9650759696960449}, {'word': \" don't\", 'start': 28.22, 'end': 28.38, 'probability': 0.9986748099327087}, {'word': ' care', 'start': 28.38, 'end': 28.56, 'probability': 0.9974727034568787}, {'word': ' if', 'start': 28.56, 'end': 28.82, 'probability': 0.6635841727256775}, {'word': ' you', 'start': 28.82, 'end': 28.9, 'probability': 0.975911021232605}, {'word': ' broke,', 'start': 28.9, 'end': 29.24, 'probability': 0.9485871195793152}, {'word': ' you', 'start': 29.46, 'end': 29.54, 'probability': 0.9879100322723389}, {'word': ' grew', 'start': 29.54, 'end': 29.78, 'probability': 0.9940251708030701}, {'word': ' up', 'start': 29.78, 'end': 29.96, 'probability': 0.9928622841835022}, {'word': ' broke.', 'start': 29.96, 'end': 30.18, 'probability': 0.9781303405761719}]}, {'id': 5, 'seek': 2344, 'start': 30.56, 'end': 34.38, 'text': \" I don't care if you grew up rich. I don't care if you're in college. You're not in college.\", 'tokens': [50704, 286, 500, 380, 1127, 498, 291, 6109, 493, 4593, 13, 286, 500, 380, 1127, 498, 291, 434, 294, 3859, 13, 509, 434, 406, 294, 3859, 13, 50916], 'temperature': 0.0, 'avg_logprob': -0.21133507777304544, 'compression_ratio': 1.8045977011494252, 'no_speech_prob': 0.1699000895023346, 'words': [{'word': ' I', 'start': 30.56, 'end': 30.62, 'probability': 0.9938021898269653}, {'word': \" don't\", 'start': 30.62, 'end': 30.72, 'probability': 0.9987530410289764}, {'word': ' care', 'start': 30.72, 'end': 30.92, 'probability': 0.9986686706542969}, {'word': ' if', 'start': 30.92, 'end': 31.04, 'probability': 0.9971349239349365}, {'word': ' you', 'start': 31.04, 'end': 31.1, 'probability': 0.9975925087928772}, {'word': ' grew', 'start': 31.1, 'end': 31.34, 'probability': 0.9966856837272644}, {'word': ' up', 'start': 31.34, 'end': 31.54, 'probability': 0.9944932460784912}, {'word': ' rich.', 'start': 31.54, 'end': 31.74, 'probability': 0.9963756203651428}, {'word': ' I', 'start': 32.2, 'end': 32.28, 'probability': 0.9935896396636963}, {'word': \" don't\", 'start': 32.28, 'end': 32.4, 'probability': 0.999536782503128}, {'word': ' care', 'start': 32.4, 'end': 32.62, 'probability': 0.998225748538971}, {'word': ' if', 'start': 32.62, 'end': 32.76, 'probability': 0.9906078577041626}, {'word': \" you're\", 'start': 32.76, 'end': 32.9, 'probability': 0.9868101477622986}, {'word': ' in', 'start': 32.9, 'end': 33.06, 'probability': 0.9937329888343811}, {'word': ' college.', 'start': 33.06, 'end': 33.38, 'probability': 0.9929752349853516}, {'word': \" You're\", 'start': 33.72, 'end': 33.82, 'probability': 0.9912827908992767}, {'word': ' not', 'start': 33.82, 'end': 34.0, 'probability': 0.9938297867774963}, {'word': ' in', 'start': 34.0, 'end': 34.16, 'probability': 0.997565507888794}, {'word': ' college.', 'start': 34.16, 'end': 34.38, 'probability': 0.9990554451942444}]}, {'id': 6, 'seek': 2344, 'start': 34.7, 'end': 42.14, 'text': ' You only get 24 hours and I blew up literally. I went from being a high school dropout to selling', 'tokens': [50916, 509, 787, 483, 4022, 2496, 293, 286, 19075, 493, 3736, 13, 286, 1437, 490, 885, 257, 1090, 1395, 3270, 346, 281, 6511, 51300], 'temperature': 0.0, 'avg_logprob': -0.21133507777304544, 'compression_ratio': 1.8045977011494252, 'no_speech_prob': 0.1699000895023346, 'words': [{'word': ' You', 'start': 34.7, 'end': 34.82, 'probability': 0.9974103569984436}, {'word': ' only', 'start': 34.82, 'end': 34.94, 'probability': 0.9845713376998901}, {'word': ' get', 'start': 34.94, 'end': 35.12, 'probability': 0.99676114320755}, {'word': ' 24', 'start': 35.12, 'end': 35.72, 'probability': 0.9934558272361755}, {'word': ' hours', 'start': 35.72, 'end': 36.26, 'probability': 0.9968660473823547}, {'word': ' and', 'start': 36.26, 'end': 36.66, 'probability': 0.4506516456604004}, {'word': ' I', 'start': 36.66, 'end': 36.92, 'probability': 0.9949401617050171}, {'word': ' blew', 'start': 36.92, 'end': 37.32, 'probability': 0.9943865537643433}, {'word': ' up', 'start': 37.32, 'end': 37.76, 'probability': 0.9987857937812805}, {'word': ' literally.', 'start': 37.76, 'end': 38.22, 'probability': 0.8815832138061523}, {'word': ' I', 'start': 38.96, 'end': 39.18, 'probability': 0.997180700302124}, {'word': ' went', 'start': 39.18, 'end': 39.32, 'probability': 0.9134053587913513}, {'word': ' from', 'start': 39.32, 'end': 39.52, 'probability': 0.9936816692352295}, {'word': ' being', 'start': 39.52, 'end': 39.68, 'probability': 0.9902077317237854}, {'word': ' a', 'start': 39.68, 'end': 39.86, 'probability': 0.966754138469696}, {'word': ' high', 'start': 39.86, 'end': 40.06, 'probability': 0.9961949586868286}, {'word': ' school', 'start': 40.06, 'end': 40.32, 'probability': 0.8853275775909424}, {'word': ' dropout', 'start': 40.32, 'end': 40.96, 'probability': 0.8851228952407837}, {'word': ' to', 'start': 40.96, 'end': 41.86, 'probability': 0.7918819189071655}, {'word': ' selling', 'start': 41.86, 'end': 42.14, 'probability': 0.996740996837616}]}, {'id': 7, 'seek': 2344, 'start': 42.14, 'end': 47.52, 'text': ' 6,000 books and less than six months. What happened? My 24 hours. I was like, okay, Eric,', 'tokens': [51300, 1386, 11, 1360, 3642, 293, 1570, 813, 2309, 2493, 13, 708, 2011, 30, 1222, 4022, 2496, 13, 286, 390, 411, 11, 1392, 11, 9336, 11, 51564], 'temperature': 0.0, 'avg_logprob': -0.21133507777304544, 'compression_ratio': 1.8045977011494252, 'no_speech_prob': 0.1699000895023346, 'words': [{'word': ' 6', 'start': 42.14, 'end': 42.44, 'probability': 0.4305104613304138}, {'word': ',000', 'start': 42.44, 'end': 42.86, 'probability': 0.9608453810214996}, {'word': ' books', 'start': 42.86, 'end': 43.1, 'probability': 0.9966055154800415}, {'word': ' and', 'start': 43.1, 'end': 43.32, 'probability': 0.42272669076919556}, {'word': ' less', 'start': 43.32, 'end': 43.42, 'probability': 0.959424614906311}, {'word': ' than', 'start': 43.42, 'end': 43.6, 'probability': 0.9962252378463745}, {'word': ' six', 'start': 43.6, 'end': 43.8, 'probability': 0.6962891817092896}, {'word': ' months.', 'start': 43.8, 'end': 44.04, 'probability': 0.9991453886032104}, {'word': ' What', 'start': 44.16, 'end': 44.26, 'probability': 0.756309449672699}, {'word': ' happened?', 'start': 44.26, 'end': 44.58, 'probability': 0.9817739129066467}, {'word': ' My', 'start': 44.9, 'end': 45.0, 'probability': 0.32256776094436646}, {'word': ' 24', 'start': 45.0, 'end': 45.42, 'probability': 0.9870175719261169}, {'word': ' hours.', 'start': 45.42, 'end': 45.82, 'probability': 0.980595588684082}, {'word': ' I', 'start': 46.62, 'end': 46.92, 'probability': 0.9468551278114319}, {'word': ' was', 'start': 46.92, 'end': 47.04, 'probability': 0.9939954876899719}, {'word': ' like,', 'start': 47.04, 'end': 47.14, 'probability': 0.9906777143478394}, {'word': ' okay,', 'start': 47.2, 'end': 47.34, 'probability': 0.6148589849472046}, {'word': ' Eric,', 'start': 47.42, 'end': 47.52, 'probability': 0.8940475583076477}]}, {'id': 8, 'seek': 2344, 'start': 47.54, 'end': 50.98, 'text': \" you gotta get a grip on your 24 hours because you're about to be broke for the rest of your life.\", 'tokens': [51564, 291, 3428, 483, 257, 12007, 322, 428, 4022, 2496, 570, 291, 434, 466, 281, 312, 6902, 337, 264, 1472, 295, 428, 993, 13, 51740], 'temperature': 0.0, 'avg_logprob': -0.21133507777304544, 'compression_ratio': 1.8045977011494252, 'no_speech_prob': 0.1699000895023346, 'words': [{'word': ' you', 'start': 47.54, 'end': 47.62, 'probability': 0.9964959025382996}, {'word': ' gotta', 'start': 47.62, 'end': 47.74, 'probability': 0.4611506462097168}, {'word': ' get', 'start': 47.74, 'end': 47.9, 'probability': 0.992803156375885}, {'word': ' a', 'start': 47.9, 'end': 47.98, 'probability': 0.9948877692222595}, {'word': ' grip', 'start': 47.98, 'end': 48.1, 'probability': 0.995789110660553}, {'word': ' on', 'start': 48.1, 'end': 48.28, 'probability': 0.9982110261917114}, {'word': ' your', 'start': 48.28, 'end': 48.38, 'probability': 0.9670273065567017}, {'word': ' 24', 'start': 48.38, 'end': 48.76, 'probability': 0.9973933696746826}, {'word': ' hours', 'start': 48.76, 'end': 49.0, 'probability': 0.9547205567359924}, {'word': ' because', 'start': 49.0, 'end': 49.14, 'probability': 0.5144679546356201}, {'word': \" you're\", 'start': 49.14, 'end': 49.32, 'probability': 0.6422661393880844}, {'word': ' about', 'start': 49.32, 'end': 49.4, 'probability': 0.8720883131027222}, {'word': ' to', 'start': 49.4, 'end': 49.54, 'probability': 0.9962702989578247}, {'word': ' be', 'start': 49.54, 'end': 49.64, 'probability': 0.997012734413147}, {'word': ' broke', 'start': 49.64, 'end': 49.86, 'probability': 0.9946905970573425}, {'word': ' for', 'start': 49.86, 'end': 50.24, 'probability': 0.9808016419410706}, {'word': ' the', 'start': 50.24, 'end': 50.32, 'probability': 0.9979128241539001}, {'word': ' rest', 'start': 50.32, 'end': 50.46, 'probability': 0.9996738433837891}, {'word': ' of', 'start': 50.46, 'end': 50.58, 'probability': 0.9992660880088806}, {'word': ' your', 'start': 50.58, 'end': 50.68, 'probability': 0.9980929493904114}, {'word': ' life.', 'start': 50.68, 'end': 50.98, 'probability': 0.9995530247688293}]}, {'id': 9, 'seek': 5098, 'start': 50.98, 'end': 54.38, 'text': \" And that's all I need you to do for me. I can tell you all about your life.\", 'tokens': [50376, 400, 300, 311, 439, 286, 643, 291, 281, 360, 337, 385, 13, 286, 393, 980, 291, 439, 466, 428, 993, 13, 50548], 'temperature': 0.0, 'avg_logprob': -0.19753646850585938, 'compression_ratio': 2.079754601226994, 'no_speech_prob': 0.031227322295308113, 'words': [{'word': ' And', 'start': 50.98, 'end': 51.44, 'probability': 0.43290361762046814}, {'word': \" that's\", 'start': 51.44, 'end': 51.7, 'probability': 0.6923971772193909}, {'word': ' all', 'start': 51.7, 'end': 51.82, 'probability': 0.990455687046051}, {'word': ' I', 'start': 51.82, 'end': 51.94, 'probability': 0.9526241421699524}, {'word': ' need', 'start': 51.94, 'end': 52.04, 'probability': 0.9929730892181396}, {'word': ' you', 'start': 52.04, 'end': 52.14, 'probability': 0.9931975603103638}, {'word': ' to', 'start': 52.14, 'end': 52.2, 'probability': 0.9826101660728455}, {'word': ' do', 'start': 52.2, 'end': 52.3, 'probability': 0.9973989725112915}, {'word': ' for', 'start': 52.3, 'end': 52.48, 'probability': 0.9945669174194336}, {'word': ' me.', 'start': 52.48, 'end': 52.62, 'probability': 0.9968006610870361}, {'word': ' I', 'start': 52.86, 'end': 52.94, 'probability': 0.9963833093643188}, {'word': ' can', 'start': 52.94, 'end': 53.08, 'probability': 0.9968439340591431}, {'word': ' tell', 'start': 53.08, 'end': 53.26, 'probability': 0.9982022047042847}, {'word': ' you', 'start': 53.26, 'end': 53.4, 'probability': 0.9967290163040161}, {'word': ' all', 'start': 53.4, 'end': 53.66, 'probability': 0.9643741846084595}, {'word': ' about', 'start': 53.66, 'end': 53.9, 'probability': 0.9989497065544128}, {'word': ' your', 'start': 53.9, 'end': 54.06, 'probability': 0.9972195625305176}, {'word': ' life.', 'start': 54.06, 'end': 54.38, 'probability': 0.9990382194519043}]}, {'id': 10, 'seek': 5098, 'start': 54.8, 'end': 58.7, 'text': \" If you just write down your 24-hour schedule for me, you let me look at it. I can tell you where you're\", 'tokens': [50548, 759, 291, 445, 2464, 760, 428, 4022, 12, 18048, 7567, 337, 385, 11, 291, 718, 385, 574, 412, 309, 13, 286, 393, 980, 291, 689, 291, 434, 50744], 'temperature': 0.0, 'avg_logprob': -0.19753646850585938, 'compression_ratio': 2.079754601226994, 'no_speech_prob': 0.031227322295308113, 'words': [{'word': ' If', 'start': 54.8, 'end': 54.86, 'probability': 0.9751833081245422}, {'word': ' you', 'start': 54.86, 'end': 54.98, 'probability': 0.9974414110183716}, {'word': ' just', 'start': 54.98, 'end': 55.16, 'probability': 0.8952131271362305}, {'word': ' write', 'start': 55.16, 'end': 55.38, 'probability': 0.5197781920433044}, {'word': ' down', 'start': 55.38, 'end': 55.78, 'probability': 0.8827145099639893}, {'word': ' your', 'start': 55.78, 'end': 55.9, 'probability': 0.564889132976532}, {'word': ' 24', 'start': 55.9, 'end': 56.28, 'probability': 0.9543282985687256}, {'word': '-hour', 'start': 56.28, 'end': 56.46, 'probability': 0.6773572564125061}, {'word': ' schedule', 'start': 56.46, 'end': 56.7, 'probability': 0.9899150133132935}, {'word': ' for', 'start': 56.7, 'end': 57.0, 'probability': 0.98304682970047}, {'word': ' me,', 'start': 57.0, 'end': 57.14, 'probability': 0.9987733960151672}, {'word': ' you', 'start': 57.18, 'end': 57.24, 'probability': 0.9250715374946594}, {'word': ' let', 'start': 57.24, 'end': 57.34, 'probability': 0.9439120888710022}, {'word': ' me', 'start': 57.34, 'end': 57.44, 'probability': 0.9996028542518616}, {'word': ' look', 'start': 57.44, 'end': 57.58, 'probability': 0.9947733283042908}, {'word': ' at', 'start': 57.58, 'end': 57.72, 'probability': 0.9992475509643555}, {'word': ' it.', 'start': 57.72, 'end': 57.8, 'probability': 0.9972928166389465}, {'word': ' I', 'start': 58.02, 'end': 58.1, 'probability': 0.9932025671005249}, {'word': ' can', 'start': 58.1, 'end': 58.22, 'probability': 0.9982580542564392}, {'word': ' tell', 'start': 58.22, 'end': 58.38, 'probability': 0.998784601688385}, {'word': ' you', 'start': 58.38, 'end': 58.48, 'probability': 0.9941774606704712}, {'word': ' where', 'start': 58.48, 'end': 58.6, 'probability': 0.8459951877593994}, {'word': \" you're\", 'start': 58.6, 'end': 58.7, 'probability': 0.8488763272762299}]}, {'id': 11, 'seek': 5098, 'start': 58.7, 'end': 61.42, 'text': \" going to be in five years. I can tell you where you're going to be in ten years. I can tell you\", 'tokens': [50744, 516, 281, 312, 294, 1732, 924, 13, 286, 393, 980, 291, 689, 291, 434, 516, 281, 312, 294, 2064, 924, 13, 286, 393, 980, 291, 50880], 'temperature': 0.0, 'avg_logprob': -0.19753646850585938, 'compression_ratio': 2.079754601226994, 'no_speech_prob': 0.031227322295308113, 'words': [{'word': ' going', 'start': 58.7, 'end': 58.78, 'probability': 0.7061402201652527}, {'word': ' to', 'start': 58.78, 'end': 58.84, 'probability': 0.9955747127532959}, {'word': ' be', 'start': 58.84, 'end': 58.92, 'probability': 0.9891968369483948}, {'word': ' in', 'start': 58.92, 'end': 59.04, 'probability': 0.8712630867958069}, {'word': ' five', 'start': 59.04, 'end': 59.16, 'probability': 0.4879867732524872}, {'word': ' years.', 'start': 59.16, 'end': 59.4, 'probability': 0.9720467329025269}, {'word': ' I', 'start': 59.62, 'end': 59.7, 'probability': 0.9953267574310303}, {'word': ' can', 'start': 59.7, 'end': 59.8, 'probability': 0.9912635087966919}, {'word': ' tell', 'start': 59.8, 'end': 59.94, 'probability': 0.9981521964073181}, {'word': ' you', 'start': 59.94, 'end': 60.02, 'probability': 0.9966220855712891}, {'word': ' where', 'start': 60.02, 'end': 60.12, 'probability': 0.7933964729309082}, {'word': \" you're\", 'start': 60.12, 'end': 60.22, 'probability': 0.9486625790596008}, {'word': ' going', 'start': 60.22, 'end': 60.28, 'probability': 0.9520473480224609}, {'word': ' to', 'start': 60.28, 'end': 60.4, 'probability': 0.9973711967468262}, {'word': ' be', 'start': 60.4, 'end': 60.42, 'probability': 0.9318879842758179}, {'word': ' in', 'start': 60.42, 'end': 60.52, 'probability': 0.9118782877922058}, {'word': ' ten', 'start': 60.52, 'end': 60.62, 'probability': 0.606005072593689}, {'word': ' years.', 'start': 60.62, 'end': 60.8, 'probability': 0.9933022260665894}, {'word': ' I', 'start': 60.98, 'end': 61.1, 'probability': 0.9781748056411743}, {'word': ' can', 'start': 61.1, 'end': 61.2, 'probability': 0.9827500581741333}, {'word': ' tell', 'start': 61.2, 'end': 61.34, 'probability': 0.9972233772277832}, {'word': ' you', 'start': 61.34, 'end': 61.42, 'probability': 0.9976544976234436}]}, {'id': 12, 'seek': 5098, 'start': 61.42, 'end': 63.16, 'text': \" where you're going to be in 20 years if you keep that schedule.\", 'tokens': [50880, 689, 291, 434, 516, 281, 312, 294, 945, 924, 498, 291, 1066, 300, 7567, 13, 51200], 'temperature': 0.0, 'avg_logprob': -0.19753646850585938, 'compression_ratio': 2.079754601226994, 'no_speech_prob': 0.031227322295308113, 'words': [{'word': ' where', 'start': 61.42, 'end': 61.54, 'probability': 0.6498516798019409}, {'word': \" you're\", 'start': 61.54, 'end': 61.64, 'probability': 0.9470682442188263}, {'word': ' going', 'start': 61.64, 'end': 61.7, 'probability': 0.9718842506408691}, {'word': ' to', 'start': 61.7, 'end': 61.74, 'probability': 0.992290198802948}, {'word': ' be', 'start': 61.74, 'end': 61.8, 'probability': 0.9854586124420166}, {'word': ' in', 'start': 61.8, 'end': 61.88, 'probability': 0.988919198513031}, {'word': ' 20', 'start': 61.88, 'end': 62.06, 'probability': 0.49098774790763855}, {'word': ' years', 'start': 62.06, 'end': 62.24, 'probability': 0.9900465607643127}, {'word': ' if', 'start': 62.24, 'end': 62.38, 'probability': 0.36761462688446045}, {'word': ' you', 'start': 62.38, 'end': 62.46, 'probability': 0.9977172613143921}, {'word': ' keep', 'start': 62.46, 'end': 62.6, 'probability': 0.9943437576293945}, {'word': ' that', 'start': 62.6, 'end': 62.76, 'probability': 0.9940568208694458}, {'word': ' schedule.', 'start': 62.76, 'end': 63.16, 'probability': 0.977622389793396}]}], 'language': 'en'}\n"
          ]
        }
      ],
      "source": [
        "model_whisper = whisper.load_model(\"base\")\n",
        "result_base = model_whisper.transcribe(audio, word_timestamps=True)\n",
        "print(result_base)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}